{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "628439\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "glove_path = '../glove.840B.300d.txt'\n",
    "android_corpus_path = '../android_dataset/corpus.tsv'\n",
    "ubuntu_corpus_path = '../ubuntu_dataset/text_tokenized.txt'\n",
    "WORD_TO_ID = 'word_to_id'\n",
    "U_ID2DATA = 'ubuntu_id_to_data'\n",
    "A_ID2DATA = 'android_id_to_data'\n",
    "\n",
    "# Processes all sentences in out datasets to give useful containers of data concerning the corpus:\n",
    "# word2id vocab \n",
    "# dict of question id to list of words in the question\n",
    "def process_whole_corpuses():\n",
    "    list_dataset_paths = [ubuntu_corpus_path, android_corpus_path]\n",
    "    all_txt = []\n",
    "    ubuntu_ids = []\n",
    "    android_ids = []\n",
    "    ubuntu_id_to_data = {}\n",
    "    android_id_to_data = {}\n",
    "    \n",
    "    for dataset_path in list_dataset_paths:\n",
    "        lines = open(dataset_path).readlines()\n",
    "        for line in lines:\n",
    "            \n",
    "            id_title_body_list = line.split('\\t')\n",
    "            idx = int(id_title_body_list[0])\n",
    "            title_plus_body = id_title_body_list[1] + ' ' + id_title_body_list[2][:-1]\n",
    "            all_txt.append(title_plus_body) \n",
    "            \n",
    "            if dataset_path == ubuntu_corpus_path: ubuntu_id_to_data[idx] = title_plus_body.split()\n",
    "            else: android_id_to_data[idx] = title_plus_body.split()\n",
    "    \n",
    "    vectorizer = CountVectorizer(binary=True, analyzer='word', token_pattern='[^\\s]+[a-z]*[0-9]*')\n",
    "    vectorizer.fit(all_txt)\n",
    "    return {WORD_TO_ID: vectorizer.vocabulary_, U_ID2DATA: ubuntu_id_to_data, A_ID2DATA: android_id_to_data}\n",
    "\n",
    "processed_corpus = process_whole_corpuses()\n",
    "\n",
    "ubuntu_id_to_data = processed_corpus[U_ID2DATA]\n",
    "android_id_to_data = processed_corpus[A_ID2DATA]\n",
    "word_to_id = processed_corpus[WORD_TO_ID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PADDING_IDX = 0\n",
    "\n",
    "# Get glove embeddings matrix only for words in our corpus (++Gain of gigabytes of memory)\n",
    "# Matrix [num_words_with_embeddings x word_dim] is be fed to pytorch nn.Embedding module without gradient\n",
    "# Function returns this nn.Embedding Object\n",
    "def load_glove_embeddings(glove_path, word_to_id_vocab, embedding_dim=300):\n",
    "    with open(glove_path) as f:\n",
    "        glove_matrix = np.zeros((len(word_to_id_vocab), embedding_dim))\n",
    "        for line in f.readlines():\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            index = word_to_id_vocab.get(word)\n",
    "            if index:\n",
    "                try:\n",
    "                    vector = np.array(values[1:], dtype='float32')\n",
    "                    glove_matrix[index] = vector\n",
    "                except: pass\n",
    "                \n",
    "    glove_matrix = torch.from_numpy(glove_matrix).float()\n",
    "    torch_embedding = nn.Embedding(glove_matrix.size(0), glove_matrix.size(1), padding_idx=PADDING_IDX)\n",
    "    torch_embedding.weight = nn.Parameter(glove_matrix)\n",
    "    torch_embedding.weight.requires_grad = False\n",
    "    \n",
    "    return torch_embedding\n",
    "\n",
    "torch_embedding = load_glove_embeddings(glove_path, word_to_id)\n",
    "\n",
    "# Returns a matrix of [num_words x word_embedding_dim] when fed with a 1D tensor of words in a sentence\n",
    "# print(torch_embedding(Variable(torch.LongTensor([22, 3]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n",
      "Variable containing:\n",
      "( 0 ,.,.) = \n",
      " -0.0850  0.5020  0.0024  ...  -0.2151 -0.2630 -0.0060\n",
      "  0.0014  0.3565 -0.0555  ...  -0.1124  0.0783  0.2240\n",
      " -0.2490  0.0878 -0.3940  ...  -0.4625  0.1552  0.3354\n",
      "           ...             â‹±             ...          \n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "[torch.FloatTensor of size 1x100x300]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "TRUNCATE_LENGTH = 100\n",
    "\n",
    "# Takes a question id and the corresponding dict of question_id_to_words\n",
    "# Builds a matrix of [1 x num_words x input_size] where first dim is for concatenation in future\n",
    "# Use up to TRUNCATE_LENGTH number of words and pad if needed\n",
    "def question_id_to_matrix(question_id, dict_qid_to_words, words_to_id_vocabulary, pytorch_embeddings):\n",
    "    question_data = dict_qid_to_words[question_id]\n",
    "    word_ids = []\n",
    "    \n",
    "    # Build list of ids of words in that question\n",
    "    for word in question_data:\n",
    "        if len(word) == 1: continue\n",
    "        if len(word_ids) == 100: break\n",
    "        word_ids.append(int(words_to_id_vocabulary[word.lower()]))\n",
    "    \n",
    "    # Pad if need more rows\n",
    "    if len(word_ids) < TRUNCATE_LENGTH: word_ids += [PADDING_IDX] * (TRUNCATE_LENGTH-len(word_ids))\n",
    "    \n",
    "    question_in_embedded_form = pytorch_embeddings(torch.LongTensor(word_ids))\n",
    "    return question_in_embedded_form.unsqueeze(0)\n",
    "\n",
    "print(question_id_to_matrix(57211, android_id_to_data, word_to_id, torch_embedding))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
